\documentclass[10pt,a4paper]{article}

% images
\usepackage[margin=1in]{geometry}
\usepackage{graphicx}
\usepackage{subfig}

% reference items
\usepackage{enumitem}

% links
\usepackage{url}
\usepackage{hyperref}

\usepackage{pdfpages}
\usepackage{pgfplots}

\usepackage{tikz}
\usetikzlibrary{arrows,automata,positioning}

\usepackage{footnote}

% maths
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{dsfont}
\usepackage{bm}

\usepackage{amsthm}

\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{claim}[theorem]{Claim}
\newtheorem{lemma}[theorem]{Lemma}

\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}

\newenvironment{subproof}[1][\proofname]{%
  \renewcommand{\qedsymbol}{$\blacksquare$}%
  \begin{proof}[#1]%
}{%
  \end{proof}%
}

\newtheorem*{claim*}{Claim}
\newtheorem*{corollary}{Corollary}
\newtheorem*{remark}{Remark}
\newtheorem*{fact}{Fact}

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
 
\newcommand{\code}[1]{\texttt{#1}}
\newcommand*\conj[1]{\overline{#1}}
\newcommand*\vect[1]{\bm{#1}}

% No section numbering
% \setcounter{secnumdepth}{0}

\bibliographystyle{siam}

\title{\textsc{CS908 Assignment 4 - Research Proposal}}
\author{Thomas Archbold}
\date{}

\begin{document}
\maketitle

% Introduction (Background, Aims, Problem Statement)
% Related Work (Academic Research, Existing Systems)
% Research Processes (Approach, Methodology)
% Project Management (Timeline, Constraints, Risk)
% Progress
% Conclusion

% Problem definition and literature review        /20
% Research methodology and viability              /40
% Project plan: time management and risk analysis /10
% Communication skills                            /30

\section{Introduction}

	Prediction markets are exchange-traded markets\footnote{A market in which
	all transactions are routed through a central source.} that trade on the
	outcome of events, as opposed to traditional financial instruments. Since
	actors in the market participate by putting up their own money in the form
	of betting on an unknown future outcome, the market prices can indicate the
	beliefs held by the market of certain events occurring. What can make these
	markets even more interesting is the ability to combine these bids on
	events in complex ways, giving users the freedom to make predictions over a
	range of different unknown outcomes. This is the approach taken by
	\emph{Predictalot}~\cite{Predictalot}, which boasts a platform on which one
	can bet on over 9.2 quintillion outcomes in the NCAA Men's College
	Basketball playoffs. This specification outlines the plans to implement a
	similar combinatorial prediction market for betting on outcomes in the 2020
	United States presidential election, placing as few restrictions as
	possible on the types of bets available to traders.

	The rest of the specification is structured as follows. In
	Section~\ref{sec:overview} we outline in greater detail the motivation for
	such a project and present our specific goals for the platform. In
	Section~\ref{sec:background} we discuss the underlying theory on which we
	will model the platform, including recent results in mechanism design for
	combinatorial auctions. We also discuss the current software that exists in
	use by others to implement other prediction markets, as well as how this
	project will fit in with the current body of work. In
	Section~\ref{sec:researchProcesses} we outline the methods and approaches
	we plan to take in order to complete this project, including a brief
	discussion of the tools, technology, and data that we plan to use. Aspects
	related to the effective management of the project are discussed in
	Section~\ref{sec:projectManagement}. We conclude with a brief discussion of
	progress made thus far in Section~\ref{sec:progress}, followed by closing
	thoughts and plans for the next stages in Section~\ref{sec:conclusion}.

\section{Project overview}
	\label{sec:overview}

	\subsection{Problem Statement}

	The goal of this project is to produce a combinatorial prediction market
	for the upcoming 2020 US presidential election and related events in the
	run up to it taking place on 3 November. Participants within this market
	will be able to place and trade bets based on what they think is likely to
	happen. The trading of bets on the outcomes may occur up to the event
	itself and the platform will update the odds accordingly. When the outcome
	of the event is realised, winnings will be paid out to those who own the
	``right'' to redeem a bet.

	This goal will be achieved by writing software on which to host such a
	market; this will be in the form of a web application written in Common
	Lisp. Moreover, the platform will allow for different auction mechanisms to
	be implemented and explored, with the aim of measuring the impact of
	varying the underlying model on the market's functionality and performance.

	\subsection{Motivation}

	Prediction markets provide ways in which to bet on the occurrence of events
	in the future, and are often used to bet on a variety of circumstances --
	this could be on the outcomes of a political election, sporting events, or
	any other probabilistic event. Since there is an incentive to do well in
	such a market, as players stake their own money, people are inclined to bet
	how they truly feel about certain events, and hence the learning of public
	sentiment on these events can effectively be crowdsourced. Combinatorial
	prediction markets, taking inspiration from the theoretical economics and
	mechanism design literature, allows for bets to be bought and sold and in
	combining these bets to keep track of the odds, we may learn how the people
	view the likelihood of related and unrelated events. With this project, we
	seek to implement a combinatorial prediction market for the 2020 US
	presidential election. There is significant global importance to the
	outcome of this and the individual events that comprise the presidential
	campaigns that it would provide useful insight into public sentiment on the
	matter -- or at least, more so than for men's college basketball.

	From the mechanism design literature, however, it is well-known that
	computing allocations of goods to buyers maximising, for example, social
	welfare or revenue, requires solving an NP-hard optimisation problem
	\cite{VCGNPhard}. Furthermore, for a market offering bets on $m$ separate
	events, there are $2^m$ possible ways of combining such bets -- how can we
	expect users to enter an exponential number of bids before they even get to
	participate in the market? These two problems are the focus of much of the
	literature within algorithmic mechanism design \cite{Nisan2001}, a subfield
	within algorithmic game theory. Broadly, this is an area of research at
	the intersection of economics and computer science that is concerned with
	designing the ways in which self-interested agents act within a strategic
	environment and achieving certain economic properties -- truthfulness,
	budget balance, individual rationality, for example -- while ensuring that
	the mechanisms remain practical to implement. It hence makes extensive use
	of techniques found in computer science, most notably asymptotic
	analysis, randomisation, and approximation. The goal in the modern
	literature therefore departs from striving to compute the idealistic but
	impractical optimal solution, towards computing ones which are
	approximately-optimal, or ``good enough''. It is with this in mind that we
	wish to explore the challenges associated with implementing such a market,
	due to its strong ties with theoretical computer science.

	Even restricting ourselves to approximately-optimal solutions, we are faced
	with yet another problem -- how do we define ``good enough''? What makes,
	say, a 4-approximation for computing an allocation in a two-sided market
	any better than a 7-approximation that also achieves group-strategy
	proofness?\footnote{These are just examples to illustrate the point --
	mechanisms achieving these guarantees may or may not exist.} The answer is
	that it depends -- trade offs must be made on a variety of assumptions on
	the structure of the market and its agents, and these parameters may be
	tweaked depending on the setting. Each of these decisions will lead to
	different mechanisms with different performance. Given that there is no
	single metric by which we can judge a mechanism's performance, this project
	also aims to implement software that is generalised enough such that it is
	capable of tweaking the parameters on the market to see what, if any,
	impact they have on the functioning of the system as a whole. Thus the
	project can serve as a platform to implement and analyse recent mechanisms
	in the literature in a practical environment.

	\subsection{Aims}

	As stated, the main aim of this project is to create a combinatorial
	prediction market for betting on outcomes in the forthcoming US
	presidential election. The underlying exchange will be modelled as variants
	of two-sided combinatorial markets (see Section~\ref{sec:background} for a
	more in-depth discussion of what this entails). To get a concrete idea of
	the features, we detail them below under the categories of \textbf{core},
	\textbf{additional}, and \textbf{stretch} features. The core features will
	implement all of the functionality to qualify the software as a
	combinatorial prediction market, and will cover making and buying basic
	bets, combining them in complex ways, and calculating the somewhat accurate
	based on the actions of the market, likely based on dummy data for testing;
	the additional features will extend this functionality so we may begin to
	explore the effects of making use of different underlying mechanisms from
	the literature; and the stretch features will focus on transitioning from
	the dummy data into the real world, as well as the provision of more
	complex bets and further refinement of the user experience.

	\subsubsection{Core features}

	\begin{itemize}
		\item ass
	\end{itemize}

	\subsubsection{Additional features}

	% two-sided exchange, where agents can make and trade bets
	\begin{itemize}
		\item Two-sided exchange 
	\end{itemize}

	\subsubsection{Stretch features}

	\begin{itemize}
		\item ass
	\end{itemize}

\section{Background}
	\label{sec:background}

	\subsection{Combinatorial auctions}

	In a single-item auction, we have a collection of $n$ agents who each
	possess a valuation for acquiring a single item on offer. A
	\emph{mechanism} is any method for allocating this item to the bidders --
	typically, this involves specifying an \emph{allocation rule} and a
	\emph{payment rule}. The former may be responsible for collecting
	information from the participants, often a bid, to compute the allocation,
	while the latter is used to ensure that agents act truthfully.

	We use the real number $v_i$ to denote agent $i$'s valuation for acquiring
	the item. This information is private to each agent (referred to as
	``bidders'' or ``buyers''), meaning neither the other agents nor the
	mechanism itself has any way of determining this value. Naturally, we
	typically wish to allocate this item to the bidder who truly values it the
	most -- that is, allocate it to agent $i^* = \argmax_{i \in [n]}
	v_i$.\footnote{We use the standard notation of $[k]$ to represent the set
	$\{ 1, \ldots, k \}$} It is a typical for an auction to elicit a bid $b_i$
	from each agent so as to acquire their valuation $v_i$ -- note, however,
	that since the agents are strategic they may lie (i.e., submit bid $b_i
	\neq v_i$) if they believe it is in their best interests. The Vickrey
	mechanism \cite{Vickrey1961} achieves such an allocation by believing the
	bidders, giving the item to the agent with the highest bid, and charging
	him the next highest bid.

	It is easy to see how this can be extended to the case of multi-item
	auctions, where we have $m$ items to allocate. Buyers now have a collection
	of valuation function, $v_i(S)$ that associate to each subset of items $S
	\subseteq [m]$ a value for acquiring this subset. Here we can see where
	sources of complexity are introduced into the model -- since the number of
	subsets of any set of size $m$ is $2^m$, we cannot hope to either collect
	all these valuations from bidders nor evaluate them in sub-exponential
	time, without imposing further restrictions. In the literature, one common
	way to deal with this obstacle is by restricting the bidders to be
	$k$-minded -- each bidder submits a maximum of $k$ bids for $k$ different
	subsets, and effectively a bid of zero for every other set. There are also
	subtleties involved in allowing items to be homogeneous, in which case the
	auction contains $m$ copies of the same item, or heterogeneous, where each
	item is unique. The idea of this project is to model bets on future
	outcomes as items, and since we will be combining different bets to learn
	about public sentiment on these outcomes, we assume the items in the
	auction to be heterogeneous. Furthermore, since we are keen to explore the
	practical performance of some of the mechanisms in the literature, we will
	often use the $k$-minded bidders model in our underlying representation of
	the auction mechanism.

	In a combinatorial auction, instead of simply maximising over $n$ numbers
	as in a single-item setting, i.e. selecting the single bidder with the
	highest bid, we must maximise over all possible allocations, wherein lies
	another source of complexity. The multi-item auction analogue to awarding
	the item to the agent who values it most is the concept of maximising
	social welfare, which we denote $W$. If we compute allocation $A = (A_1,
	\ldots, A_n)$, where agent $i$ is allocated subset $A_i$, then the value we
	are maximising as a function of this allocation is $W(A) = \sum_{i \in [n]}
	v_i(A_i)$. The analogue to the Vickrey auction in the multi-item setting,
	the Vickrey-Clarke-Groves mechanism \cite{Vickrey1961, Clarke1971,
	Groves1973} again believes the bidders and awards subsets to agents who
	value them most and charges each bidder their \emph{externality}, or the
	extra cost in social welfare incurred by that agent participating in the
	auction.

	Up until now we have assumed that the auction itself holds the items --
	this will not be the case in our prediction market since the agents
	themselves will make and hence hold the bets. It is therefore useful to
	have the concept of a \emph{two-sided} market. This comprises a set of two
	distinct types of agents: sellers, who initially hold the items for sale,
	and buyers, who are interested in buying the items from the sellers. Using
	the model of Colini-Baldeschi et al.~\cite{ColiniBaldeschi2017}, formally a
	two-sided market is a tuple $(n, m, k, I, G, F)$, where $[n]$ is the set of
	buyers, $[m]$ is the set of sellers, $[k]$ is the set of items, and $I =
	(I_1, \ldots, I_m)$ is the \emph{initial endowment}, such that $I_j$ is the
	set of items initially held by seller $j$. Vectors $G = (G_1, \ldots, G_n)$
	and $F = (F_1, \ldots, F_m)$ are the distributions from which the buyers'
	are sellers' valuation functions are assumed to be drawn, respectively. The
	notion of an allocation changes only slightly under this model: given a
	two-sided market, our aim is to redistribute the items among the agents so
	as to maximise the social welfare. An allocation is hence a pair of vectors
	$(X,Y) = ((X_1, \ldots, X_n), (Y_1, \ldots, Y_m))$ such that the union of
	$X$ and $Y$ is the set of items $[k]$, and $X_1, \ldots, X_n, Y_1, \ldots,
	Y_m$ are mutually disjoint, meaning no two agents are allocated the same
	item. As before, buyers have a valuation $v_i(S)$ for each subset of items
	$S$, and we introduce the same idea for the sellers, which we denote
	$w_j(S)$. Our goal is still to maximise the social welfare, which we now
	write as: \begin{equation*} W(X, Y) = \sum_{i \in [n]} v_i(X_i) + \sum_{j
	\in [m]} w_j(Y_j) \end{equation*}

	We conclude our discussion of the underlying by introducing some of the
	main economic properties pursued in the field of mechanism design, useful
	in our discussion of the current literature:

	\begin{itemize}
		\item \textbf{Incentive Compatibility (IC):} agents are incentivised to
			bid truthfully (i.e. submitting $b_i = v_i$) as they can do no
			better by lying -- truth-telling is a \emph{dominant strategy}.

		\item \textbf{Individual Rationality (IR):} it is not harmful for any
			agent to participate in the market, meaning in any trade there is a
			strategy that yields a utility that is no less than their initial
			utility. Note that this says nothing about the outcome of the event
			-- agents may still experience a net loss for having purchased a
			bet which turned out to be false.

		\item \textbf{Budget Balance (BB):} the sum of all payments is at least
			zero, meaning no extra funds have to be supplied to subsidise the
			market.

	\end{itemize}

	Now we have all we need to discuss recent results in the literature on
	algorithmic mechanism design for combinatorial auctions.

	\subsection{Related academic work}

	Algorithmic mechanism design enjoys much attention in the setting of
	combinatorial auctions, where there is much opportunity to make use of
	traditional techniques from theoretical computer science. Much of this is
	inspired by a question first posed by Nisan and Ronen~\cite{Nisan2001},
	which asks whether the requirement for dominant strategy incentive
	compatibility inherently degrades a mechanism's approximation ratio -- put
	another way, if mechanism design is inherently harder than algorithm
	design. This question is covered in part by Daniely, Schapira, and
	Shahaf~\cite{Daniely2018}, who present various inapproximability results
	for deterministic, truthful mechanisms. Specifically, they show that for
	general valuation functions no computationally-efficient mechanism may
	achieve better performance than the trivial $m$-approximation, which
	collects all items into a single bundle and awards it to the highest bidder
	for the price of the second-highest bid, while remaining truthful.
	Colini-Baldeschi et al.~\cite{ColiniBaldeschi2017} make use of
	randomisation to present three constant-factor approximation mechanisms for
	two-sided combinatorial markets, and experiment with various assumptions on
	the structure of the agents' valuations. In particular, they provide three
	6-approximation mechanisms which achieve individual rationality, incentive
	compatibility, and a stronger notion of budget balance which they term
	Direct Trade Strong Budget Balance (DSBB).

	% DA auctions - single-minded

	\subsection{Existing systems}

	Prediction markets are not a novel concept and there are several examples
	of recent systems for various settings. This project's conception was
	initially inspired by the author's discovery, at the suggestion of
	supervisor Matthias Englert, of \emph{Predictalot} \cite{Predictalot}, a
	combinatorial prediction market for betting on the outcomes of a wide range
	of events in the NCAA Men's College basketball playoffs. It launched as a
	Yahoo! app in 2010, though it appears to have since been abandoned.
	Nonetheless, it boasts the ability to bet on ``almost anything you can
	think of, like \emph{Duke will advance further than UNC}''. Specifically,
	the tournament is structured such that the top 64 college basketball teams
	play 63 games in a single elimination tournament, while \emph{Predictalot}
	keeps track of the odds, computing them by scanning through all the
	predictions placed so far. They note that an exact computation of the odds
	is \#P-hard -- as hard as counting the number of variable assignments that
	satisfy a given CNF formula, or how many subsets of a list of integers sum
	to zero -- hence justifying their decision to approximate the odds by
	random sampling of the outcome space. They also emphasise that they keep
	track of all different possible outcomes, resulting in odds that are
	interconnected in natural ways -- betting on a team to make the final will
	have an effect on the odds of each stage, since the team must win at each
	of these stages to reach the final in the first place. Given the apparent
	power behind this idea, it would be interesting to apply it to a setting
	with perhaps more significance, such as the upcoming presidential
	elections.

	\emph{Augur} \cite{Augur} is more recent example, and in July 2018 became
	the first decentralised prediction market, launched on the Ethereum
	blockchain.  Similarly to how this project will be structured, \emph{Augur}
	hosts the prediction market in two phases: the market stage, where users
	are able to trade shares between each other, and the arbitration stage,
	where the market's outcome is determined. However, \emph{Augur} makes use
	of fees to subsidise the arbitration process, breaking the budget balance
	property discussed earlier. This makes it less appealing, as money is
	required to be fed into the system in order for it to function.

	Both \emph{PredictIt} \cite{PredictIt} and the Iowa Electronic Markets
	(IEM) \cite{IEM} provide the ability to make bets on various political
	events, including on outcomes within the 2020 US presidential election.
	However, like \emph{Augur}, they do not provide the ability to combine
	these bets in complex ways and hence this is a gap that this project aims
	to fill.

	This project will differ from these mainly in the fact that we will
	implement a combinatorial prediction market, with a focus on making bets on
	a combination of outcomes -- the only similar existing software
	implementing this was \emph{Predictalot}, which is no longer maintained or
	even accessible. Betting on collections of events better incorporates
	conditional information into the market price, hence giving a more
	realistic view of how events are related. The project will also differ in
	the means by which users will interact with the markets. Specifically, on
	each of the existing systems discussed, the prices of bets are shown and it
	is up to the user if they wish to participate in the trade at that price.
	This project will model these interactions more akin to sealed-bid
	auctions, with the intention that bidders will place and buy bets that
	align more closely with their true beliefs. Moreover, placing such
	additional restrictions on how agents interact with the market allows for
	more guarantees to be made regarding the outcomes of transactions and
	allows more easily for results from the current literature to be
	implemented. Of course, it will be an important design decision to ensure
	the system both achieves these guarantees but is not too restrictive for
	the agents so as to render the interactions contrived and unnatural.

% Research Processes (Approach, Methodology)
\section{Research Processes}
	\label{sec:researchProcesses}

	\subsection{Approach}

	\subsection{Tools}

\section{Project Management}
	\label{sec:projectManagement}

\section{Progress}
	\label{sec:progress}

\section{Conclusion}
	\label{sec:conclusion}

\bibliography{bibliography}

\end{document}
